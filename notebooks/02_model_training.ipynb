{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from pathlib import Path\n",
    "from src.model.train import compute_metrics\n",
    "import numpy as np\n",
    "import json\n",
    "import collections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a mock training process\n",
    "\n",
    "A pre-trained model is downloaded from huggingface model hub \n",
    "and then saved as is to the model directory.\n",
    "\n",
    "This model is then used to generate predictions on the test data.\n",
    "The predictions are used to evaluate the model's performance.\n",
    "The results are saved to the models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and tokenizer to /Users/shestaka/tweet_sentiment_classification/models/cardiffnlp/twitter-roberta-base-sentiment-latest\n"
     ]
    }
   ],
   "source": [
    "work_dir = Path(\".\").absolute().parent\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "model_dir = work_dir / \"models\" / model_name\n",
    "model = transformers.pipeline(\"text-classification\", model=model_name, tokenizer=model_name)\n",
    "model.model.save_pretrained(model_dir)\n",
    "model.tokenizer.save_pretrained(model_dir)\n",
    "print(f\"Saved model and tokenizer to {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_precision': {'negative': 0.6198347107438017, 'neutral': 0.775, 'positive': 0.6859756097560976, 'micro_avg': 0.6695437731196054, 'macro_avg': 0.693603440166633, 'weighted_avg': 0.6958899452722606}, 'test_recall': {'negative': 0.872093023255814, 'neutral': 0.32978723404255317, 'positive': 0.8302583025830258, 'micro_avg': 0.6695437731196054, 'macro_avg': 0.6773795199604643, 'weighted_avg': 0.6695437731196054}, 'test_f1_score': {'negative': 0.7246376811594203, 'neutral': 0.4626865671641791, 'positive': 0.7512520868113522, 'micro_avg': 0.6695437731196054, 'macro_avg': 0.6461921117116506, 'weighted_avg': 0.6424456833604258}, 'test_support': {'negative': 258.0, 'neutral': 282.0, 'positive': 271.0, 'micro_avg': nan, 'macro_avg': nan, 'weighted_avg': nan}}\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_from_disk(work_dir / \"data/processed/test\")\n",
    "class_label = dataset.features['label']\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for batch in model(KeyDataset(dataset, \"text\"), batch_size=8):\n",
    "    test_results.append(batch)\n",
    "\n",
    "results = datasets.Dataset.from_list(test_results).rename_column(\"label\", \"pred_label\")\n",
    "results = datasets.concatenate_datasets(\n",
    "    [dataset, results], axis=1\n",
    ")\n",
    "\n",
    "predictions = np.asarray(class_label.str2int(results[\"pred_label\"]))\n",
    "label_ids = results[\"label\"]\n",
    "\n",
    "eval_predictions = transformers.EvalPrediction(predictions=predictions, label_ids=label_ids)\n",
    "metrics = compute_metrics(eval_predictions)\n",
    "\n",
    "\n",
    "renamed_metrics = collections.defaultdict(dict)\n",
    "prefix = \"test_\"\n",
    "for metric, values in metrics.items(): \n",
    "    for key, val in values.items():\n",
    "        if key.startswith(\"label_\"):\n",
    "            label_id = int(key.split(\"_\")[1])\n",
    "            label = class_label.int2str(label_id)\n",
    "            renamed_metrics[f\"{prefix}{metric}\"][label] = val\n",
    "        else:\n",
    "            renamed_metrics[f\"{prefix}{metric}\"][key] = val\n",
    "renamed_metrics = dict(renamed_metrics)\n",
    "print(renamed_metrics)\n",
    "\n",
    "with open(model_dir  / \"test_results.json\", \"w\") as f:\n",
    "    json.dump(renamed_metrics, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
